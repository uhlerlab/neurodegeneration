{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "import os\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "from skimage.filters import gaussian\n",
    "from skimage.morphology import remove_small_objects\n",
    "from scipy.ndimage import center_of_mass\n",
    "from stardist.models import StarDist2D\n",
    "from csbdeep.utils import normalize\n",
    "from skimage.segmentation import clear_border\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "channelNames=['Tau','Abeta','MAP2','LMNB','DAPI']\n",
    "dataDir='/data/xzhang/neuro_new/newdata/tauAbeta_tiff'\n",
    "segsavepath=os.path.join(dataDir,'segmentations')\n",
    "if not os.path.exists(segsavepath):\n",
    "    os.mkdir(segsavepath)\n",
    "savedir_processed=os.path.join(dataDir,'processed')\n",
    "if not os.path.exists(savedir_processed):\n",
    "    os.mkdir(savedir_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n"
     ]
    }
   ],
   "source": [
    "model_stardist = StarDist2D.from_pretrained('2D_versatile_fluo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaleFactor=0.1626/0.2031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for path in os.listdir(dataDir):\n",
    "    print(path)\n",
    "    if not os.path.exists(os.path.join(segsavepath,path)):\n",
    "        os.mkdir(os.path.join(segsavepath,path))\n",
    "    for fname in os.listdir(os.path.join(dataDir,path)):\n",
    "        if '.npy' not in fname:\n",
    "            continue\n",
    "        pID=fname[:-4]\n",
    "        print(pID)\n",
    "        if os.path.exists(os.path.join(segsavepath,path,pID+'.tif')):\n",
    "            print('skip segmented')\n",
    "            continue\n",
    "        img2d=np.load(os.path.join(dataDir,path,pID+'.npy'))[4]\n",
    "        print(img2d.shape)\n",
    "        labeled_nuclei, linfo = model_stardist.predict_instances(gaussian(normalize(img2d),5/scaleFactor))\n",
    "        io.imsave(os.path.join(segsavepath,path,pID+'.tif'),labeled_nuclei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allCoord=None\n",
    "allImgNames=None\n",
    "allPatientID=None\n",
    "allCat=None\n",
    "allHC_staci=None\n",
    "allHC_std=None\n",
    "\n",
    "imgSize_target=128\n",
    "imgSize=imgSize_target*scaleFactor\n",
    "radius=int(imgSize/2)\n",
    "minNucSize=300\n",
    "laminThreshold=0.3 #by area\n",
    "minmaxScale=[(10,99.99),(90,99.99),(10,99.99),(10,99.99),(10,99.99)]\n",
    "abetaDist=[400,800]\n",
    "\n",
    "allAbeta_mean={400:[],800:[]}\n",
    "allAbeta_area={400:[],800:[]}\n",
    "\n",
    "for path in os.listdir(dataDir):\n",
    "    print(path)\n",
    "    for fname in os.listdir(os.path.join(dataDir,path)):\n",
    "        if '.npy' not in fname:\n",
    "            continue\n",
    "        pID=fname[:-4]\n",
    "        print(pID)\n",
    "        img2d=np.load(os.path.join(dataDir,path,pID+'.npy')).astype(float)\n",
    "        imgSeg=io.imread(os.path.join(segsavepath,path,pID+'.tif'))\n",
    "        \n",
    "        #scale intensity\n",
    "        for c in range(img2d.shape[0]):\n",
    "#             if c!=4:\n",
    "#                 continue\n",
    "            img2d[c]=np.clip(img2d[c],np.percentile(img2d,minmaxScale[c][0]),np.percentile(img2d,minmaxScale[c][1]))\n",
    "            img2d[c]=(img2d[c]-np.min(img2d[c]))/(np.max(img2d[c])-np.min(img2d[c]))\n",
    "        \n",
    "        #HC of cells\n",
    "        currCoord=np.zeros((np.unique(imgSeg).size-1,2))\n",
    "        currHC_staci=np.zeros(np.unique(imgSeg).size-1)\n",
    "        currHC_std=np.zeros(np.unique(imgSeg).size-1)\n",
    "        imgCount=0\n",
    "        for idx in np.unique(imgSeg):\n",
    "            if idx==0:\n",
    "                continue\n",
    "            current_nuc=imgSeg==idx\n",
    "            \n",
    "            x,y = center_of_mass(current_nuc)\n",
    "            x=int(x)\n",
    "            y=int(y)\n",
    "            if x-radius<0 or x+radius>(img2d.shape[1]) or y-radius<0 or y+radius>(img2d.shape[2]):\n",
    "                continue\n",
    "            \n",
    "            if np.sum(current_nuc)<minNucSize:\n",
    "                lmnbPix=img2d[3][current_nuc]>0\n",
    "                if np.sum(lmnbPix)/np.sum(current_nuc)<laminThreshold:\n",
    "                    continue\n",
    "            \n",
    "            currImgs_0=np.copy(img2d[4,x-radius:x+radius,y-radius:y+radius])\n",
    "            currImgs_0_seg=imgSeg[x-radius:x+radius,y-radius:y+radius]\n",
    "            currImgs_0[currImgs_0_seg!=idx]=0\n",
    "            currHC_staci_thresh= (0.4*np.max(currImgs_0) + np.min(currImgs_0[currImgs_0_seg==idx]) + 0.35*(np.max(currImgs_0)-np.min(currImgs_0[currImgs_0_seg==idx])))/2\n",
    "            currHC_std_thresh=np.mean(currImgs_0)+1.5*np.std(currImgs_0)\n",
    "            currHC_staci[imgCount]=np.sum(currImgs_0>currHC_staci_thresh)/np.sum(currImgs_0>0)\n",
    "            currHC_std[imgCount]=np.sum(currImgs_0>currHC_std_thresh)/np.sum(currImgs_0>0)\n",
    "            currCoord[imgCount]=np.array([x,y])\n",
    "            \n",
    "            imgCount+=1\n",
    "        currHC_staci=currHC_staci[:imgCount]\n",
    "        currHC_std=currHC_std[:imgCount]\n",
    "        currCoord=currCoord[:imgCount]\n",
    "        currImgName=np.repeat(pID,imgCount)\n",
    "        currPatientID=np.repeat(pID.split('-')[0]+'-'+pID.split('-')[1],imgCount)\n",
    "        currCat=np.repeat(path,imgCount)\n",
    "        if allCoord is None:\n",
    "            allImgNames=currImgName\n",
    "            allCoord=currCoord\n",
    "            allPatientID=currPatientID\n",
    "            allCat=currCat\n",
    "            allHC_staci=currHC_staci\n",
    "            allHC_std=currHC_std\n",
    "        else:\n",
    "            allImgNames=np.concatenate((allImgNames,currImgName))\n",
    "            allCoord=np.concatenate((allCoord,currCoord),axis=0)\n",
    "            allPatientID=np.concatenate((allPatientID,currPatientID))\n",
    "            allCat=np.concatenate((allCat,currCat))\n",
    "            allHC_staci=np.concatenate((allHC_staci,currHC_staci))\n",
    "            allHC_std=np.concatenate((allHC_std,currHC_std))\n",
    "        \n",
    "        #abeta - threshold; mean intensity within a distance\n",
    "        # threshold -> abeta pixel counts within a distance\n",
    "        for d in abetaDist:\n",
    "            print('dist', d)\n",
    "            currABmean=np.zeros(imgCount)-1\n",
    "            currABarea=np.zeros(imgCount)-1\n",
    "            for idx in range(imgCount):\n",
    "                x,y=currCoord[idx].astype(int)\n",
    "                radiusAB=int(d/2)\n",
    "                if x-radiusAB<0 or x+radiusAB>(img2d.shape[1]) or y-radiusAB<0 or y+radiusAB>(img2d.shape[2]):\n",
    "                    continue\n",
    "                currImgs_ab=img2d[1,x-radiusAB:x+radiusAB,y-radiusAB:y+radiusAB]\n",
    "                currABmean[idx]=np.mean(currImgs_ab)\n",
    "                currABarea[idx]=np.sum(currImgs_ab>0)/currImgs_ab.size\n",
    "            allAbeta_area[d]=np.concatenate((allAbeta_area[d],currABarea))\n",
    "            allAbeta_mean[d]=np.concatenate((allAbeta_mean[d],currABmean))\n",
    "            \n",
    "\n",
    "with open(os.path.join(savedir_processed,'allImgNames'), 'wb') as output:\n",
    "    pickle.dump(allImgNames, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(savedir_processed,'allCoord'), 'wb') as output:\n",
    "    pickle.dump(allCoord, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(savedir_processed,'allPatientID'), 'wb') as output:\n",
    "    pickle.dump(allPatientID, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(savedir_processed,'allHC_staci'), 'wb') as output:\n",
    "    pickle.dump(allHC_staci, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(savedir_processed,'allHC_std'), 'wb') as output:\n",
    "    pickle.dump(allHC_std, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(savedir_processed,'allAbeata_mean'), 'wb') as output:\n",
    "    pickle.dump(allAbeta_mean, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(savedir_processed,'allAbeata_area'), 'wb') as output:\n",
    "    pickle.dump(allAbeta_area, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(savedir_processed,'allCat'), 'wb') as output:\n",
    "    pickle.dump(allCat, output, pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allCoord=None\n",
    "allImgNames=None\n",
    "allPatientID=None\n",
    "allCat=None\n",
    "allHC_staci=None\n",
    "allHC_std=None\n",
    "\n",
    "imgSize_target=128\n",
    "imgSize=imgSize_target*scaleFactor\n",
    "radius=int(imgSize/2)\n",
    "minNucSize=300\n",
    "laminThreshold=0.3 #by area\n",
    "minmaxScale=[(10,99.99),(90,99.99),(10,99.99),(10,99.99),(10,99.99)]\n",
    "abetaDist=[400,800]\n",
    "\n",
    "allAbeta_mean={400:[],800:[]}\n",
    "allAbeta_area={400:[],800:[]}\n",
    "\n",
    "for path in os.listdir(dataDir):\n",
    "    print(path)\n",
    "    for fname in os.listdir(os.path.join(dataDir,path)):\n",
    "        if '.npy' not in fname:\n",
    "            continue\n",
    "        pID=fname[:-4]\n",
    "        print(pID)\n",
    "        img2d=np.load(os.path.join(dataDir,path,pID+'.npy')).astype(float)\n",
    "        imgSeg=io.imread(os.path.join(segsavepath,path,pID+'.tif'))\n",
    "        \n",
    "        #scale intensity\n",
    "        for c in range(img2d.shape[0]):\n",
    "#             if c!=4:\n",
    "#                 continue\n",
    "            img2d[c]=np.clip(img2d[c],np.percentile(img2d,minmaxScale[c][0]),np.percentile(img2d,minmaxScale[c][1]))\n",
    "            img2d[c]=(img2d[c]-np.min(img2d[c]))/(np.max(img2d[c])-np.min(img2d[c]))\n",
    "        \n",
    "        #HC of cells\n",
    "        currCoord=np.zeros((np.unique(imgSeg).size-1,2))\n",
    "        currHC_staci=np.zeros(np.unique(imgSeg).size-1)\n",
    "        currHC_std=np.zeros(np.unique(imgSeg).size-1)\n",
    "        imgCount=0\n",
    "        for idx in np.unique(imgSeg):\n",
    "            if idx==0:\n",
    "                continue\n",
    "            current_nuc=imgSeg==idx\n",
    "            \n",
    "            x,y = center_of_mass(current_nuc)\n",
    "            x=int(x)\n",
    "            y=int(y)\n",
    "            if x-radius<0 or x+radius>(img2d.shape[1]) or y-radius<0 or y+radius>(img2d.shape[2]):\n",
    "                continue\n",
    "            \n",
    "            if np.sum(current_nuc)<minNucSize:\n",
    "                lmnbPix=img2d[3][current_nuc]>0\n",
    "                if np.sum(lmnbPix)/np.sum(current_nuc)<laminThreshold:\n",
    "                    continue\n",
    "            currCoord[imgCount]=np.array([x,y])\n",
    "            \n",
    "            \n",
    "            \n",
    "            imgCount+=1\n",
    "        currCoord=currCoord[:imgCount]\n",
    "        currImgName=np.repeat(pID,imgCount)\n",
    "        currPatientID=np.repeat(pID.split('-')[0]+'-'+pID.split('-')[1],imgCount)\n",
    "        currCat=np.repeat(path,imgCount)\n",
    "        print(imgCount)\n",
    "        if allCoord is None:\n",
    "            allImgNames=currImgName\n",
    "            allCoord=currCoord\n",
    "            allPatientID=currPatientID\n",
    "            allCat=currCat\n",
    "        else:\n",
    "            allImgNames=np.concatenate((allImgNames,currImgName))\n",
    "            allCoord=np.concatenate((allCoord,currCoord),axis=0)\n",
    "            allPatientID=np.concatenate((allPatientID,currPatientID))\n",
    "            allCat=np.concatenate((allCat,currCat))\n",
    "        \n",
    "            \n",
    "\n",
    "with open(os.path.join(savedir_processed,'allImgNames'), 'wb') as output:\n",
    "    pickle.dump(allImgNames, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(savedir_processed,'allCoord'), 'wb') as output:\n",
    "    pickle.dump(allCoord, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(savedir_processed,'allPatientID'), 'wb') as output:\n",
    "    pickle.dump(allPatientID, output, pickle.HIGHEST_PROTOCOL)\n",
    "with open(os.path.join(savedir_processed,'allCat'), 'wb') as output:\n",
    "    pickle.dump(allCat, output, pickle.HIGHEST_PROTOCOL)\n",
    "# with open(os.path.join(savedir_processed,'allHC_staci'), 'wb') as output:\n",
    "#     pickle.dump(allHC_staci, output, pickle.HIGHEST_PROTOCOL)\n",
    "# with open(os.path.join(savedir_processed,'allHC_std'), 'wb') as output:\n",
    "#     pickle.dump(allHC_std, output, pickle.HIGHEST_PROTOCOL)\n",
    "# with open(os.path.join(savedir_processed,'allAbeata_mean'), 'wb') as output:\n",
    "#     pickle.dump(allAbeta_mean, output, pickle.HIGHEST_PROTOCOL)\n",
    "# with open(os.path.join(savedir_processed,'allAbeata_area'), 'wb') as output:\n",
    "#     pickle.dump(allAbeta_area, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(savedir_processed,'allHC_staci'), 'rb') as output:\n",
    "    allHC_staci=pickle.load(output)\n",
    "with open(os.path.join(savedir_processed,'allHC_std'), 'rb') as output:\n",
    "    allHC_std=pickle.load(output)\n",
    "with open(os.path.join(savedir_processed,'allAbeata_mean'), 'rb') as output:\n",
    "    allAbeta_mean=pickle.load( output)\n",
    "with open(os.path.join(savedir_processed,'allAbeata_area'), 'rb') as output:\n",
    "    allAbeta_area=pickle.load(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allImgs=None\n",
    "\n",
    "imgSize_target=128\n",
    "imgSize=imgSize_target*scaleFactor\n",
    "radius=int(imgSize/2)\n",
    "minNucSize=300\n",
    "laminThreshold=0.3 #by area\n",
    "minmaxScale=[(10,99.99),(90,99.99),(10,99.99),(10,99.99),(10,99.99)]\n",
    "\n",
    "for path in os.listdir(dataDir):\n",
    "    print(path)\n",
    "    for fname in os.listdir(os.path.join(dataDir,path)):\n",
    "        if '.npy' not in fname:\n",
    "            continue\n",
    "        pID=fname[:-4]\n",
    "        print(pID)\n",
    "        img2d=np.load(os.path.join(dataDir,path,pID+'.npy')).astype(float)\n",
    "        imgSeg=io.imread(os.path.join(segsavepath,path,pID+'.tif'))\n",
    "        \n",
    "        #scale intensity\n",
    "        for c in range(img2d.shape[0]):\n",
    "#             if c!=4:\n",
    "#                 continue\n",
    "            img2d[c]=np.clip(img2d[c],np.percentile(img2d,minmaxScale[c][0]),np.percentile(img2d,minmaxScale[c][1]))\n",
    "            img2d[c]=(img2d[c]-np.min(img2d[c]))/(np.max(img2d[c])-np.min(img2d[c]))\n",
    "        \n",
    "        currImgs=np.zeros((np.unique(imgSeg).size-1,5,imgSize_target,imgSize_target))\n",
    "        imgCount=0\n",
    "        for idx in np.unique(imgSeg):\n",
    "            if idx==0:\n",
    "                continue\n",
    "            current_nuc=imgSeg==idx\n",
    "            \n",
    "            x,y = center_of_mass(current_nuc)\n",
    "            x=int(x)\n",
    "            y=int(y)\n",
    "            if x-radius<0 or x+radius>(img2d.shape[1]) or y-radius<0 or y+radius>(img2d.shape[2]):\n",
    "                continue\n",
    "            \n",
    "            if np.sum(current_nuc)<minNucSize:\n",
    "                lmnbPix=img2d[3][current_nuc]>0\n",
    "                if np.sum(lmnbPix)/np.sum(current_nuc)<laminThreshold:\n",
    "                    continue\n",
    "            \n",
    "            \n",
    "            currImgs_0=np.copy(img2d[4,x-radius:x+radius,y-radius:y+radius])\n",
    "            currImgs_0_seg=imgSeg[x-radius:x+radius,y-radius:y+radius]\n",
    "            currImgs_0[currImgs_0_seg!=idx]=0\n",
    "            \n",
    "            currImgs_2=np.copy(img2d[3,x-radius:x+radius,y-radius:y+radius])\n",
    "            currImgs_2[currImgs_0_seg!=idx]=0\n",
    "            \n",
    "            currImgs[imgCount,0]=cv2.resize(currImgs_0, (imgSize_target,imgSize_target)) #dapi\n",
    "            currImgs[imgCount,1]=cv2.resize(img2d[2,x-radius:x+radius,y-radius:y+radius], (imgSize_target,imgSize_target)) #map2\n",
    "            currImgs[imgCount,3]=cv2.resize(img2d[1,x-radius:x+radius,y-radius:y+radius], (imgSize_target,imgSize_target)) #abeta\n",
    "            currImgs[imgCount,2]=cv2.resize(currImgs_2, (imgSize_target,imgSize_target)) #lmnb\n",
    "            currImgs[imgCount,4]=cv2.resize(img2d[0,x-radius:x+radius,y-radius:y+radius], (imgSize_target,imgSize_target)) #tau\n",
    "            \n",
    "            imgCount+=1\n",
    "        currImgs=currImgs[:imgCount]\n",
    "        if allImgs is None:\n",
    "            allImgs=currImgs\n",
    "        else:\n",
    "            allImgs=np.concatenate((allImgs,currImgs))\n",
    "        \n",
    "            \n",
    "\n",
    "with open(os.path.join(savedir_processed,'allImgs_minmax_segNuc'), 'wb') as output:\n",
    "    pickle.dump(allImgs, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
