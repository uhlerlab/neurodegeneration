{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "# import scanpy\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import models.modelsCNN as modelsCNN\n",
    "import models.optimizer as optimizer\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import gc\n",
    "from skimage import io\n",
    "import scipy.stats\n",
    "import utils.plot\n",
    "import models.train_metaClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "\n",
    "resolution='5'\n",
    "savedir_baseline='/data/xzhang/neuro/results/jointClustering/baseline/res'+resolution\n",
    "with open(os.path.join(savedir_baseline,'pca_dapi_600'), 'rb') as output:\n",
    "    pca_dapi=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'pca_gfap_600'), 'rb') as output:\n",
    "    pca_gfap=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'pca_map2_600'), 'rb') as output:\n",
    "    pca_map2=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'pca_lmnb_600'), 'rb') as output:\n",
    "    pca_lmnb=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'modAll'), 'rb') as output:\n",
    "    modAll=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'silAll'), 'rb') as output:\n",
    "    silAll=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'moddapi'), 'rb') as output:\n",
    "    moddapi=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'sildapi'), 'rb') as output:\n",
    "    sildapi=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'modgfap'), 'rb') as output:\n",
    "    modgfap=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'silgfap'), 'rb') as output:\n",
    "    silgfap=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'modmap2'), 'rb') as output:\n",
    "    modmap2=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'silmap2'), 'rb') as output:\n",
    "    silmap2=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'modlmnb'), 'rb') as output:\n",
    "    modlmnb=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'sillmnb'), 'rb') as output:\n",
    "    sillmnb=pickle.load(output)\n",
    "with open(os.path.join(savedir_baseline,'leidenRes3_10samples'), 'rb') as output:\n",
    "    leidenResAll=pickle.load(output)\n",
    "    \n",
    "savedir_processed='/data/xzhang/neuro/processed'\n",
    "resDir='/data/xzhang/neuro/results/plots/cnnvaeexp0_segNucall'\n",
    "saveDir=os.path.join(savedir_baseline,'cnnvaeexp0_segNucall')\n",
    "if not os.path.exists(saveDir):\n",
    "    os.mkdir(saveDir)\n",
    "\n",
    "\n",
    "with open(os.path.join(resDir,'leiden_res'+resolution), 'rb') as output:\n",
    "    finalPartition=pickle.load(output)\n",
    "    \n",
    "jointPartition=np.copy(finalPartition)\n",
    "modFrac=0.3\n",
    "modFrac_dapi=(moddapi/modAll>modFrac).astype(int)\n",
    "modFrac_map2=(modmap2/modAll>modFrac).astype(int)\n",
    "modFrac_gfap=(modgfap/modAll>modFrac).astype(int)\n",
    "modFrac_lmnb=(modlmnb/modAll>modFrac).astype(int)\n",
    "modFrac_sum=modFrac_dapi+modFrac_gfap+modFrac_lmnb+modFrac_map2\n",
    "\n",
    "silAll_mean=np.zeros(np.unique(jointPartition).size)\n",
    "for c in np.unique(jointPartition):\n",
    "    silAll_mean[c]=np.mean(silAll[jointPartition==c])\n",
    "    \n",
    "sildapi_mean=np.zeros(np.unique(jointPartition).size)\n",
    "for c in np.unique(jointPartition):\n",
    "    sildapi_mean[c]=np.mean(sildapi[jointPartition==c])\n",
    "    \n",
    "silgfap_mean=np.zeros(np.unique(jointPartition).size)\n",
    "for c in np.unique(jointPartition):\n",
    "    silgfap_mean[c]=np.mean(silgfap[jointPartition==c])\n",
    "\n",
    "silmap2_mean=np.zeros(np.unique(jointPartition).size)\n",
    "for c in np.unique(jointPartition):\n",
    "    silmap2_mean[c]=np.mean(silmap2[jointPartition==c])\n",
    "sillmnb_mean=np.zeros(np.unique(jointPartition).size)\n",
    "for c in np.unique(jointPartition):\n",
    "    sillmnb_mean[c]=np.mean(sillmnb[jointPartition==c])\n",
    "silAll_pos=np.zeros(np.unique(jointPartition).size)\n",
    "for c in np.unique(jointPartition):\n",
    "    silAll_pos[c]=np.sum(silAll[jointPartition==c]>0)/np.sum(jointPartition==c)\n",
    "sildapi_pos=np.zeros(np.unique(jointPartition).size)\n",
    "for c in np.unique(jointPartition):\n",
    "    sildapi_pos[c]=np.sum(sildapi[jointPartition==c]>0)/np.sum(jointPartition==c)\n",
    "silmap2_pos=np.zeros(np.unique(jointPartition).size)\n",
    "for c in np.unique(jointPartition):\n",
    "    silmap2_pos[c]=np.sum(silmap2[jointPartition==c]>0)/np.sum(jointPartition==c)\n",
    "silgfap_pos=np.zeros(np.unique(jointPartition).size)\n",
    "for c in np.unique(jointPartition):\n",
    "    silgfap_pos[c]=np.sum(silgfap[jointPartition==c]>0)/np.sum(jointPartition==c)\n",
    "sillmnb_pos=np.zeros(np.unique(jointPartition).size)\n",
    "for c in np.unique(jointPartition):\n",
    "    sillmnb_pos[c]=np.sum(sillmnb[jointPartition==c]>0)/np.sum(jointPartition==c)\n",
    "\n",
    "silmean_frac=0.3\n",
    "silmean_frac_neg=2\n",
    "def comparesilmean(sildapi_mean,silAll_mean,silmean_frac,silmean_frac_neg):\n",
    "    silmean_frac_dapi=np.zeros(silAll_mean.size)\n",
    "    sildapi_mean_posIdx=np.arange(silAll_mean.size)[sildapi_mean>0]\n",
    "    sildapi_mean_negIdx=np.arange(silAll_mean.size)[sildapi_mean<0]\n",
    "#     print(sildapi_mean_negIdx[sildapi_mean[sildapi_mean<0]>(silAll_mean[sildapi_mean<0]*silmean_frac_neg)])\n",
    "    silmean_frac_dapi[sildapi_mean_posIdx[sildapi_mean[sildapi_mean>0]>(silAll_mean[sildapi_mean>0]*silmean_frac)]]=1\n",
    "    silmean_frac_dapi[sildapi_mean_negIdx[sildapi_mean[sildapi_mean<0]>(silAll_mean[sildapi_mean<0]*silmean_frac_neg)]]=1\n",
    "\n",
    "    return silmean_frac_dapi\n",
    "\n",
    "silmean_frac_dapi=comparesilmean(sildapi_mean,silAll_mean,silmean_frac,silmean_frac_neg)\n",
    "silmean_frac_gfap=comparesilmean(silgfap_mean,silAll_mean,silmean_frac,silmean_frac_neg)\n",
    "silmean_frac_map2=comparesilmean(silmap2_mean,silAll_mean,silmean_frac,silmean_frac_neg)\n",
    "silmean_frac_lmnb=comparesilmean(sillmnb_mean,silAll_mean,silmean_frac,silmean_frac_neg)\n",
    "\n",
    "silmean_frac_sum=silmean_frac_dapi+silmean_frac_gfap+silmean_frac_map2+silmean_frac_lmnb\n",
    "\n",
    "silpos_frac=0.3\n",
    "silpos_dapi=(sildapi_pos/silAll_pos>silpos_frac).astype(int)\n",
    "silpos_gfap=(silgfap_pos/silAll_pos>silpos_frac).astype(int)\n",
    "silpos_map2=(silmap2_pos/silAll_pos>silpos_frac).astype(int)\n",
    "silpos_lmnb=(sillmnb_pos/silAll_pos>silpos_frac).astype(int)\n",
    "\n",
    "silPos_sum=silpos_dapi+silpos_gfap+silpos_map2+silpos_lmnb\n",
    "\n",
    "\n",
    "clusterIdx_pass=np.arange(np.unique(finalPartition).size)[(modFrac_sum>1)+(silmean_frac_sum>1)+(silPos_sum>1)]\n",
    "\n",
    "nsamples=10\n",
    "leidenJoint_overlap=np.zeros((np.unique(jointPartition).size,nsamples))\n",
    "for cj in np.unique(jointPartition):\n",
    "    for s in range(nsamples):\n",
    "        _,counts=np.unique(leidenResAll[jointPartition==cj,s],return_counts=True)\n",
    "        leidenJoint_overlap[cj,s]=np.max(counts)/np.sum(jointPartition==cj)\n",
    "\n",
    "overlap_mean=np.mean(leidenJoint_overlap,axis=1)\n",
    "overlap_std=np.std(leidenJoint_overlap,axis=1)\n",
    "\n",
    "overlap_mean=np.mean(leidenJoint_overlap,axis=1)\n",
    "overlap_std=np.std(leidenJoint_overlap,axis=1)\n",
    "\n",
    "randomAll=np.zeros((leidenResAll.shape[0],nsamples)).astype(int)\n",
    "\n",
    "for s in range(nsamples):\n",
    "    randomS=np.copy(jointPartition)\n",
    "    np.random.seed(s)\n",
    "    np.random.shuffle(randomS)\n",
    "\n",
    "    randomAll[:,s]=randomS\n",
    "leidenJoint_overlap_random=np.zeros((np.unique(jointPartition).size,nsamples))\n",
    "for cj in np.unique(jointPartition):\n",
    "    for s in range(nsamples):\n",
    "        _,counts=np.unique(randomAll[jointPartition==cj,s],return_counts=True)\n",
    "        leidenJoint_overlap_random[cj,s]=np.max(counts)/np.sum(jointPartition==cj)\n",
    "\n",
    "overlap_mean_random=np.mean(leidenJoint_overlap_random,axis=1)\n",
    "overlap_std_random=np.std(leidenJoint_overlap_random,axis=1)\n",
    "\n",
    "clusterIdx_robust=np.arange(np.unique(finalPartition).size)[(overlap_mean-overlap_std)>(overlap_mean_random+overlap_std_random)]\n",
    "finalPartition_keep=np.intersect1d(clusterIdx_robust,clusterIdx_pass)\n",
    "\n",
    "\n",
    "    \n",
    "with open(os.path.join(savedir_processed,'meta_processed'), 'rb') as output:\n",
    "    meta=pickle.load(output)\n",
    "\n",
    "# annoUsed=np.array(['AAO', 'AAD', 'Duration', 'Gender','Clinical Diag','Brain Weight', 'Mutations',\n",
    "#                    'APOE', 'Braak Tau', 'Thal Phase', 'CERAD', 'CAA', 'SVD','alpha-syn', 'TDP43'])\n",
    "annoUsed=np.array(['Path Diag','Clinical Diag','Brain Weight', 'Mutations',\n",
    "                   'APOE', 'Braak Tau', 'Thal Phase', 'CERAD', 'CAA', 'SVD','alpha-syn', 'TDP43',\n",
    "                   'AAO', 'AAD', 'Duration', 'Gender'])\n",
    "annoUsed_numeric=np.array(['AAO', 'AAD', 'Duration','Brain Weight','Braak Tau', 'Thal Phase', 'CERAD', 'CAA', 'SVD'])\n",
    "\n",
    "meta=meta[annoUsed]\n",
    "stains=np.array(['DAPI','GFAP','MAP2','LMNB'])\n",
    "\n",
    "    \n",
    "finalPartition_keepIdx=np.repeat(False, finalPartition.size)\n",
    "for c in finalPartition_keep:\n",
    "    finalPartition_keepIdx[finalPartition==c]=True\n",
    "finalPartition_keep_input=np.copy(finalPartition)\n",
    "finalPartition_keep_input[np.logical_not(finalPartition_keepIdx)]=-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(savedir_processed,'allPatientID'), 'rb') as output:\n",
    "    allPatientIDs=pickle.load(output)\n",
    "meta=meta.loc[np.unique(allPatientIDs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(finalPartition_keep).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(savedir_processed,'allImgNames'), 'rb') as output:\n",
    "    allImgNames=pickle.load(output)\n",
    "print(np.unique(allImgNames).size)\n",
    "print(np.unique(allPatientIDs).size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatialRegions=[300,650,1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get cluster composition\n",
    "sUnique_all=np.unique(allImgNames)\n",
    "inputDict={}\n",
    "clusterRes_i=finalPartition_keep_input[finalPartition_keepIdx]\n",
    "clusterUnique=np.unique(clusterRes_i)\n",
    "for sr in spatialRegions:\n",
    "    with open(os.path.join(savedir_baseline,'clusterPlots','neighborhood_allCells_counts_'+str(sr)), 'rb') as output:\n",
    "        neigh=pickle.load(output)\n",
    "    inputCluster=np.zeros((sUnique_all.size,clusterUnique.size))\n",
    "    for i in range(sUnique_all.size):\n",
    "        imgIdx_i=allImgNames[finalPartition_keepIdx]==sUnique_all[i]\n",
    "        for j in range(clusterUnique.size):\n",
    "            cellIdx=np.logical_and(clusterRes_i==clusterUnique[j],imgIdx_i)\n",
    "            if np.sum(cellIdx)>0:\n",
    "                inputCluster[i,j]=np.mean(neigh[cellIdx])\n",
    "    inputDict[sr]=inputCluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 68)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputDict[sr].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seeds=[4,8,9,10,11,12]\n",
    "for anno in ['APOE']:\n",
    "    print(anno)\n",
    "    regrs=False\n",
    "    if anno in annoUsed_numeric:\n",
    "        regrs=True\n",
    "    if anno in annoUsed_numeric:\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    #construct labels\n",
    "    \n",
    "    meta['keep']=True\n",
    "    if anno not in annoUsed_numeric:\n",
    "        pathDiag_unique_keep,pathDiag_inverse_keep,pathDiag_counts_keep=np.unique(meta[anno].astype(str),return_counts=True,return_inverse=True)\n",
    "        pathDiag_unique_keep[pathDiag_counts_keep<=1]='remove'\n",
    "        pathDiag_unique_keep=pathDiag_unique_keep[pathDiag_inverse_keep]\n",
    "\n",
    "        meta['keep']=pathDiag_unique_keep!='remove'\n",
    "    \n",
    "    meta_allcells=meta.loc[allPatientIDs][anno].to_numpy().astype(str)\n",
    "    cellIdx=np.logical_and(meta_allcells!='na',meta_allcells!='nan')\n",
    "    cellIdx=np.logical_and(cellIdx,meta.loc[allPatientIDs]['keep'].to_numpy())\n",
    "    allCat=meta_allcells[cellIdx]\n",
    "    \n",
    "    allImgNames_a=allImgNames[cellIdx]\n",
    "    sUnique,sidx_start=np.unique(allImgNames_a,return_index=True)\n",
    "    \n",
    "\n",
    "    if anno not in annoUsed_numeric:\n",
    "        pathDiag_unique,labels,pathDiag_counts=np.unique(allCat[sidx_start],return_counts=True,return_inverse=True)\n",
    "        weights=np.sum(pathDiag_counts)/pathDiag_counts\n",
    "    else:\n",
    "        pathDiag_unique=None\n",
    "        weights=None\n",
    "        labels=allCat[sidx_start].astype(float)\n",
    "    if labels.size<2:\n",
    "        continue\n",
    "    annoName=anno\n",
    "    if ' ' in anno:\n",
    "        annoName=anno.split(' ')\n",
    "        annoName=annoName[0]+'_'+annoName[1]\n",
    "    for seed in seeds:\n",
    "        print('seed: ',seed)\n",
    "        for sr in spatialRegions:\n",
    "            print('spatial ',sr)\n",
    "            _,idx,_=np.intersect1d(sUnique_all,sUnique,return_indices=True)\n",
    "            inputAll=inputDict[sr][idx]\n",
    "            name='exp0_allMetaClf_nucSeg_modSilFilter_2_res5_seed'+str(seed)+'_'+annoName+'_'+str(sr)\n",
    "            savepath_curr=os.path.join(saveDir,'metadataClf_counts',name)\n",
    "            if not os.path.exists(os.path.join(saveDir,'metadataClf_counts')):\n",
    "                os.mkdir(os.path.join(saveDir,'metadataClf_counts'))\n",
    "            if not os.path.exists(savepath_curr):\n",
    "                os.mkdir(savepath_curr)\n",
    "            logsavepath=os.path.join(savepath_curr,'log')\n",
    "            modelsavepath=os.path.join(savepath_curr,'model')\n",
    "            plotsavepath=os.path.join(savepath_curr,'plots')\n",
    "\n",
    "    #         if os.path.exists(os.path.join(plotsavepath,'predictions'+str(5900)+'.csv')):\n",
    "    #             continue\n",
    "\n",
    "            if not os.path.exists(logsavepath):\n",
    "                os.mkdir(logsavepath)\n",
    "            if not os.path.exists(modelsavepath):\n",
    "                os.mkdir(modelsavepath)\n",
    "            if not os.path.exists(plotsavepath):\n",
    "                os.mkdir(plotsavepath)\n",
    "\n",
    "            pIDList=allPatientIDs[sidx_start]\n",
    "            models.train_metaClf.train_metaClf(inputAll, pathDiag_unique, labels, logsavepath, modelsavepath, plotsavepath, pIDList, allImgNames, sidx_start,weights=weights, use_cuda=True, seed=seed, testepoch=3500, epochs=4000, saveFreq=500, lr=0.001, weight_decay=0, batchsize=32, model_str='fc3', fc_dim=256,regrs=regrs,update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot density\n",
    "plotsavepath='/data/xzhang/neuro/results/jointClustering/baseline/res5/cnnvaeexp0_segNucall/metadataClf_counts/plots'\n",
    "if not os.path.exists(plotsavepath):\n",
    "    os.mkdir(plotsavepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterRes_i=finalPartition_keep_input[finalPartition_keepIdx]\n",
    "clusterUnique=np.unique(clusterRes_i)\n",
    "anno='APOE'\n",
    "meta['keep']=True\n",
    "if anno not in annoUsed_numeric:\n",
    "    pathDiag_unique_keep,pathDiag_inverse_keep,pathDiag_counts_keep=np.unique(meta[anno].astype(str),return_counts=True,return_inverse=True)\n",
    "    pathDiag_unique_keep[pathDiag_counts_keep<=1]='remove'\n",
    "    pathDiag_unique_keep=pathDiag_unique_keep[pathDiag_inverse_keep]\n",
    "\n",
    "    meta['keep']=pathDiag_unique_keep!='remove'\n",
    "for sr in spatialRegions:\n",
    "    \n",
    "    meta_allcells=meta.loc[allPatientIDs][anno].to_numpy().astype(str)\n",
    "    cellIdx=np.logical_and(meta_allcells!='na',meta_allcells!='nan')\n",
    "    cellIdx=np.logical_and(cellIdx,meta.loc[allPatientIDs]['keep'].to_numpy())\n",
    "    allCat=meta_allcells[cellIdx]\n",
    "\n",
    "    allImgNames_a=allImgNames[cellIdx]\n",
    "    sUnique,sidx_start=np.unique(allImgNames_a,return_index=True)\n",
    "\n",
    "    pathDiag_unique,labels,pathDiag_counts=np.unique(allCat[sidx_start],return_counts=True,return_inverse=True)\n",
    "    _,idx,_=np.intersect1d(sUnique_all,sUnique,return_indices=True)\n",
    "    inputAll=inputDict[sr][idx]\n",
    "    input_pos=inputAll[labels==1]\n",
    "    input_neg=inputAll[labels==0]\n",
    "    input_plot=np.zeros((inputAll.shape[1],2))\n",
    "    input_plot[:,0]=np.mean(input_neg,axis=0)\n",
    "    input_plot[:,1]=np.mean(input_pos,axis=0)\n",
    "\n",
    "    vmax=np.max(input_plot)\n",
    "    vmin=np.median(input_plot)-(np.max(input_plot)-np.median(input_plot))\n",
    "    figsize=(3,15)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    im = ax.imshow(input_plot,cmap='bwr',vmin=vmin,vmax=vmax)\n",
    "    ax.set_yticks(np.arange(input_plot.shape[0]))\n",
    "    ax.set_yticklabels(clusterUnique)\n",
    "    ax.set_xticks(np.arange(input_plot.shape[1]))\n",
    "    ax.set_xticklabels([0,1])\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",rotation_mode=\"anchor\")\n",
    "    fig.colorbar(im)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(plotsavepath,anno+'_'+str(sr)+'.pdf'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 68)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_plot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterRes_i=finalPartition_keep_input[finalPartition_keepIdx]\n",
    "clusterUnique=np.unique(clusterRes_i)\n",
    "anno='APOE'\n",
    "meta['keep']=True\n",
    "if anno not in annoUsed_numeric:\n",
    "    pathDiag_unique_keep,pathDiag_inverse_keep,pathDiag_counts_keep=np.unique(meta[anno].astype(str),return_counts=True,return_inverse=True)\n",
    "    pathDiag_unique_keep[pathDiag_counts_keep<=1]='remove'\n",
    "    pathDiag_unique_keep=pathDiag_unique_keep[pathDiag_inverse_keep]\n",
    "\n",
    "    meta['keep']=pathDiag_unique_keep!='remove'\n",
    "for sr in spatialRegions:\n",
    "    \n",
    "    meta_allcells=meta.loc[allPatientIDs][anno].to_numpy().astype(str)\n",
    "    cellIdx=np.logical_and(meta_allcells!='na',meta_allcells!='nan')\n",
    "    cellIdx=np.logical_and(cellIdx,meta.loc[allPatientIDs]['keep'].to_numpy())\n",
    "    allCat=meta_allcells[cellIdx]\n",
    "\n",
    "    allImgNames_a=allImgNames[cellIdx]\n",
    "    sUnique,sidx_start=np.unique(allImgNames_a,return_index=True)\n",
    "\n",
    "    pathDiag_unique,labels,pathDiag_counts=np.unique(allCat[sidx_start],return_counts=True,return_inverse=True)\n",
    "    _,idx,_=np.intersect1d(sUnique_all,sUnique,return_indices=True)\n",
    "    inputAll=inputDict[sr][idx]\n",
    "    input_pos=inputAll[labels==1]\n",
    "    input_neg=inputAll[labels==0]\n",
    "    input_plot=np.concatenate((input_pos,input_neg),axis=0)\n",
    "\n",
    "    vmax=np.max(input_plot)\n",
    "    vmin=np.median(input_plot)-(np.max(input_plot)-np.median(input_plot))\n",
    "    figsize=(15,6)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    im = ax.imshow(input_plot,cmap='bwr',vmin=vmin,vmax=vmax)\n",
    "    ax.set_xticks(np.arange(input_plot.shape[1]))\n",
    "    ax.set_xticklabels(clusterUnique)\n",
    "    ax.set_yticks([0,np.sum(labels==1)])\n",
    "    ax.set_yticklabels([pathDiag_unique[1],pathDiag_unique[0]])\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",rotation_mode=\"anchor\")\n",
    "    fig.colorbar(im)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(plotsavepath,anno+'_'+str(sr)+'_all.pdf'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/xzhang/neuro/results/jointClustering/baseline/res5/clusterPlots/ls_cc_level1Val', 'rb') as output:\n",
    "    ls_cc_fin_clusters=pickle.load(output)\n",
    "cnames,corder=np.unique(ls_cc_fin_clusters[1000],return_inverse=True)\n",
    "\n",
    "clusterRes_i=finalPartition_keep_input[finalPartition_keepIdx]\n",
    "clusterUnique=np.unique(clusterRes_i)\n",
    "anno='APOE'\n",
    "meta['keep']=True\n",
    "if anno not in annoUsed_numeric:\n",
    "    pathDiag_unique_keep,pathDiag_inverse_keep,pathDiag_counts_keep=np.unique(meta[anno].astype(str),return_counts=True,return_inverse=True)\n",
    "    pathDiag_unique_keep[pathDiag_counts_keep<=1]='remove'\n",
    "    pathDiag_unique_keep=pathDiag_unique_keep[pathDiag_inverse_keep]\n",
    "\n",
    "    meta['keep']=pathDiag_unique_keep!='remove'\n",
    "for sr in spatialRegions:\n",
    "    meta_allcells=meta.loc[allPatientIDs][anno].to_numpy().astype(str)\n",
    "    cellIdx=np.logical_and(meta_allcells!='na',meta_allcells!='nan')\n",
    "    cellIdx=np.logical_and(cellIdx,meta.loc[allPatientIDs]['keep'].to_numpy())\n",
    "    allCat=meta_allcells[cellIdx]\n",
    "\n",
    "    allImgNames_a=allImgNames[cellIdx]\n",
    "    sUnique,sidx_start=np.unique(allImgNames_a,return_index=True)\n",
    "\n",
    "    pathDiag_unique,labels,pathDiag_counts=np.unique(allCat[sidx_start],return_counts=True,return_inverse=True)\n",
    "    _,idx,_=np.intersect1d(sUnique_all,sUnique,return_indices=True)\n",
    "    inputAll=inputDict[sr][idx]\n",
    "    input_pos=inputAll[labels==1]\n",
    "    input_neg=inputAll[labels==0]\n",
    "    input_plot=np.zeros((inputAll.shape[1],2))\n",
    "    input_plot[:,0]=np.mean(input_neg,axis=0)\n",
    "    input_plot[:,1]=np.mean(input_pos,axis=0)\n",
    "\n",
    "    vmax=np.max(input_plot)\n",
    "    vmin=np.median(input_plot)-(np.max(input_plot)-np.median(input_plot))\n",
    "    figsize=(3,15)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    im = ax.imshow(input_plot[corder],cmap='bwr',vmin=vmin,vmax=vmax)\n",
    "    ax.set_yticks(np.arange(input_plot.shape[0]))\n",
    "    ax.set_yticklabels(clusterUnique[corder])\n",
    "    ax.set_xticks(np.arange(input_plot.shape[1]))\n",
    "    ax.set_xticklabels([0,1])\n",
    "    plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",rotation_mode=\"anchor\")\n",
    "    fig.colorbar(im)\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(os.path.join(plotsavepath,anno+'_'+str(sr)+'Ordered.pdf'))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### integrated gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import sys\n",
    "sys.path.append('/home/xzhang/anaconda3/envs/neuro/lib/python3.10/site-packages/')\n",
    "from captum.attr import IntegratedGradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### igResControl\n",
    "-> use controls as baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APOE\n",
      "seed:  4\n",
      "spatial  300\n",
      "spatial  650\n",
      "spatial  1000\n",
      "seed:  8\n",
      "spatial  300\n",
      "spatial  650\n",
      "spatial  1000\n",
      "seed:  9\n",
      "spatial  300\n",
      "spatial  650\n",
      "spatial  1000\n",
      "seed:  10\n",
      "spatial  300\n",
      "spatial  650\n",
      "spatial  1000\n",
      "seed:  11\n",
      "spatial  300\n",
      "spatial  650\n",
      "spatial  1000\n",
      "seed:  12\n",
      "spatial  300\n",
      "spatial  650\n",
      "spatial  1000\n"
     ]
    }
   ],
   "source": [
    "seeds=[4,8,9,10,11,12]\n",
    "annoPlot_cat=np.array(['APOE','TDP43'])\n",
    "annoPlot_baseline={'Path Diag':'Control',\n",
    "                   'Clinical Diag':'Control',\n",
    "                   'APOE':'33',\n",
    "                   'TDP43':'0.0',\n",
    "                   'alpha-syn':'0.0'}\n",
    "\n",
    "for anno in annoPlot_cat:\n",
    "    print(anno)\n",
    "    regrs=False\n",
    "        \n",
    "    \n",
    "    #construct labels\n",
    "    \n",
    "    meta['keep']=True\n",
    "    if anno not in annoUsed_numeric:\n",
    "        pathDiag_unique_keep,pathDiag_inverse_keep,pathDiag_counts_keep=np.unique(meta[anno].astype(str),return_counts=True,return_inverse=True)\n",
    "        pathDiag_unique_keep[pathDiag_counts_keep<=1]='remove'\n",
    "        pathDiag_unique_keep=pathDiag_unique_keep[pathDiag_inverse_keep]\n",
    "\n",
    "        meta['keep']=pathDiag_unique_keep!='remove'\n",
    "    \n",
    "    meta_allcells=meta.loc[allPatientIDs][anno].to_numpy().astype(str)\n",
    "    cellIdx=np.logical_and(meta_allcells!='na',meta_allcells!='nan')\n",
    "    cellIdx=np.logical_and(cellIdx,meta.loc[allPatientIDs]['keep'].to_numpy())\n",
    "    allCat=meta_allcells[cellIdx]\n",
    "    \n",
    "    allImgNames_a=allImgNames[cellIdx]\n",
    "    sUnique,sidx_start=np.unique(allImgNames_a,return_index=True)\n",
    "    \n",
    "    pathDiag_unique,labels,pathDiag_counts=np.unique(allCat[sidx_start],return_counts=True,return_inverse=True)\n",
    "    weights=np.sum(pathDiag_counts)/pathDiag_counts\n",
    "    if labels.size<2:\n",
    "        continue\n",
    "    annoName=anno\n",
    "    if ' ' in anno:\n",
    "        annoName=anno.split(' ')\n",
    "        annoName=annoName[0]+'_'+annoName[1]\n",
    "        \n",
    "    true_label=np.copy(pathDiag_unique[labels]).astype(str)\n",
    "    for seed in seeds:\n",
    "        print('seed: ',seed)\n",
    "        for sr in spatialRegions:\n",
    "            print('spatial ',sr)\n",
    "            _,idx,_=np.intersect1d(sUnique_all,sUnique,return_indices=True)\n",
    "            inputAll=inputDict[sr][idx]\n",
    "            inputBaseline=inputAll[true_label==annoPlot_baseline[anno]]\n",
    "            \n",
    "            name='exp0_allMetaClf_nucSeg_modSilFilter_2_res5_seed'+str(seed)+'_'+annoName+'_'+str(sr)\n",
    "            savepath_curr=os.path.join(saveDir,'metadataClf_counts',name)\n",
    "            logsavepath=os.path.join(savepath_curr,'log')\n",
    "            modelsavepath=os.path.join(savepath_curr,'model')\n",
    "            plotsavepath=os.path.join(savepath_curr,'plots')\n",
    "\n",
    "    #         if os.path.exists(os.path.join(plotsavepath,'predictions'+str(5900)+'.csv')):\n",
    "    #             continue\n",
    "\n",
    "            pIDList=allPatientIDs[sidx_start]\n",
    "\n",
    "            use_cuda=True\n",
    "            testepoch=3500\n",
    "            batchsize=32\n",
    "            model_str='fc3'\n",
    "            fc_dim=256\n",
    "\n",
    "            fc_dim1=fc_dim\n",
    "            fc_dim2=fc_dim\n",
    "            fc_dim3=fc_dim\n",
    "\n",
    "            if regrs:\n",
    "                nclasses=1\n",
    "            else:\n",
    "                nclasses=np.unique(labels).size\n",
    "\n",
    "            igRes=np.zeros_like(inputAll)\n",
    "            igResPred=np.zeros_like(inputAll)\n",
    "\n",
    "            for patientIDX in range(np.unique(pIDList).size):\n",
    "                patientID=np.unique(pIDList)[patientIDX]\n",
    "        #         print(patientID,patientIDX)\n",
    "                sampleIdx=np.arange(inputAll.shape[0])[pIDList==patientID]\n",
    "                trainIdx=np.arange(inputAll.shape[0])[pIDList!=patientID]\n",
    "\n",
    "                inputAll_t=torch.tensor(inputAll[sampleIdx],requires_grad=True).cuda().float()\n",
    "                for ibIdx in range(inputBaseline.shape[0]):\n",
    "                    inputBaseline_t=torch.tensor(inputBaseline[[ibIdx]],requires_grad=True).cuda().float()\n",
    "        #             labels=torch.tensor(labels).cuda().long()\n",
    "\n",
    "                    torch.manual_seed(seed)\n",
    "                    if use_cuda:\n",
    "                        torch.cuda.manual_seed(seed)\n",
    "\n",
    "                    nfeatures=inputAll.shape[1]\n",
    "\n",
    "                    model = modelsCNN.FC_l3(nfeatures,fc_dim1,fc_dim2,fc_dim3,nclasses,0.5,regrs=regrs)\n",
    "                    if use_cuda:\n",
    "                        model.cuda()\n",
    "\n",
    "                    model.load_state_dict(torch.load(os.path.join(modelsavepath,patientID+'_'+str(testepoch)+'.pt')))\n",
    "                    with torch.no_grad():\n",
    "                        model.cuda()\n",
    "                        model.eval()\n",
    "                        ig = IntegratedGradients(model)\n",
    "                        attributions= ig.attribute(inputAll_t, baselines=inputBaseline_t,target=torch.tensor(labels[sampleIdx]).cuda())\n",
    "                        igRes[sampleIdx]+=attributions.cpu().numpy()\n",
    "\n",
    "                        pred = model(inputAll_t)\n",
    "                        attributions= ig.attribute(inputAll_t, baselines=inputBaseline_t,target=torch.argmax(pred,axis=1))\n",
    "                        igResPred[sampleIdx]+=attributions.cpu().numpy()\n",
    "            igRes=igRes/inputBaseline.shape[0]\n",
    "            igResPred=igResPred/inputBaseline.shape[0]\n",
    "            with open(os.path.join(plotsavepath,'igResControl_'+str(testepoch)), 'wb') as output:\n",
    "                pickle.dump(igRes,output,pickle.HIGHEST_PROTOCOL)\n",
    "            with open(os.path.join(plotsavepath,'igResControlPred_'+str(testepoch)), 'wb') as output:\n",
    "                pickle.dump(igResPred,output,pickle.HIGHEST_PROTOCOL)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
